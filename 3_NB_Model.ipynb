{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f0af83b-bd58-4719-bcd8-70536297f95d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff0d4ad-31e4-4633-a144-8add4405080f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from warnings import filterwarnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "import mlflow\n",
    "import datetime\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8003fab3-3d23-4f50-8e3c-25099f73e82f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Read Data from Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1feba2d3-95f8-4976-bc33-0473d3e0cb66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = spark.sql(\"select * from feature_store.customer_sentiment_analysis\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "485822d3-7bee-4614-b6c0-2a4ce7a62f19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Checking Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f2599da-4e16-46e8-a57a-7e9c7a001112",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.value_counts('Sentiment').reset_index().plot.bar(x='Sentiment')\n",
    "\n",
    "# Class imbalance exits, let's treat it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb3ba8b1-df7b-4fe9-b7b0-57b4831d926b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "max_count = data.Sentiment.value_counts().max()\n",
    "max_category = data.Sentiment.value_counts().sort_values(ascending=False).index[0]\n",
    "up_sampled_dataframe = pd.DataFrame()\n",
    "\n",
    "# Upsampling the minority categories\n",
    "for sentiment_category in data.Sentiment.unique():\n",
    "    n_count=data[data['Sentiment']==sentiment_category]['Sentiment'].count()\n",
    "    multiplyfactor = int(math.ceil(max_count/n_count))\n",
    "    print('category ',sentiment_category)\n",
    "    print('count :',n_count)\n",
    "    print('multiply_fac',multiplyfactor)\n",
    "    for i in range(0,multiplyfactor):\n",
    "        up_sampled_dataframe= pd.concat([up_sampled_dataframe,data[data['Sentiment']==sentiment_category]])\n",
    "\n",
    "# set sample size to maximum sample size\n",
    "sample_size = max_count\n",
    "df_equal_overall = pd.DataFrame()\n",
    "for i in up_sampled_dataframe.Sentiment.unique():\n",
    "  X = up_sampled_dataframe[up_sampled_dataframe.Sentiment == i].sample(sample_size)\n",
    "  df_equal_overall = df_equal_overall.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d45f306c-068a-4869-bdbe-052c8693a3fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Checking Class Imblance now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "031be1ef-e651-4c64-bdb5-0e1ad6e57a18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_equal_overall.value_counts('Sentiment').reset_index().plot.bar(x='Sentiment')\n",
    "\n",
    "# Class imbalance doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0673be4e-f8fc-479e-b211-a930946ea43a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1adeff0-f45a-40a7-8ba7-d798ad7d3666",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "x_data = data['combined_cleaned_lemmatized']\n",
    "y_data = data['Sentiment']\n",
    "X_train,X_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.2,stratify=y_data,random_state=44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45582077-2647-4e4c-bf32-5583bc6dfce8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b489aac0-c28a-43f5-be8e-da6861570e56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def metric_for_model(actual,pred):\n",
    "    accuracy_score1 = accuracy_score(actual,pred)\n",
    "    confusion_matrix1 = confusion_matrix(actual,pred)\n",
    "    classification_report1= classification_report(actual,pred)\n",
    "    f1_score1=f1_score(actual,pred,average='weighted')\n",
    "    precision_score1=precision_score(actual,pred,average='weighted')\n",
    "    recall_score1=recall_score(actual,pred,average='weighted')   \n",
    "    return accuracy_score1, confusion_matrix1, classification_report1,f1_score1,precision_score1,recall_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a49c8ef1-d095-4ac5-88cf-e58730f30861",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Base Model\n",
    "model_name='Naive Bayes'\n",
    "mlflow.set_experiment(experiment_id=\"2555925875978836\")\n",
    "with mlflow.start_run() as run:\n",
    "        current_datetime = datetime.datetime.now()\n",
    "        model = Pipeline([('vectorize',CountVectorizer(ngram_range=(1,2))),\n",
    "                ('tfidf',TfidfTransformer()),\n",
    "                ('clf',MultinomialNB())])\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred_model = model.predict(X_test)\n",
    "        (as1,cm1,cr1,f1s1,ps1,rs1)=metric_for_model(y_test,y_pred_model)\n",
    "        print(f'{model_name} Model ')\n",
    "        print('Accuracy Score : %s' %as1)\n",
    "        print('Precision Score : %s' %ps1)\n",
    "        print('Recall Score : %s' %rs1)\n",
    "        print('F1 Score : %s' %f1s1)\n",
    "        print('Confusion Matrix : %s' %cm1)\n",
    "        print('Classification Report : %s' %cr1)\n",
    "        mlflow.log_param('Model',f\"{model_name}\")\n",
    "        mlflow.log_param('Params',f\"{model_name}\")\n",
    "        mlflow.log_metric('Accuracy Score',as1)\n",
    "        mlflow.log_metric('Precision Score',ps1)\n",
    "        mlflow.log_metric('Recall Score',rs1)\n",
    "        mlflow.log_metric('F1 Score',f1s1)\n",
    "        mlflow.log_param('Confusion Matrix',cm1)\n",
    "        mlflow.log_param('Classification Report',cr1)\n",
    "        try:\n",
    "                mlflow.sklearn.log_model(model,f'{model_name}')\n",
    "                modelpath=f'/dbfs/group1_mlops/model/{model_name}/'\n",
    "                mlflow.sklearn.save_model(model,modelpath)\n",
    "                best_run=run.info\n",
    "        except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbca3419-17a0-4c65-823d-7c1056c81d53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3_NB_Model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
